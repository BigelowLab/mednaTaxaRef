---
title: "RL_MeDNA"
author: "BYDavis"
date: "2023-07-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script to serve as a location to compile, test, and ensure functionality of the code to create the Maine eDNA reference library database
Only put code in here once it has been reviewed separately



# Package and dependency installation
```{r package_loading, echo = FALSE} 
if (!require("stringr")) {install.packages("stringr"); require("stringr")} # used for species list cleaning
if (!require("dplyr")) {install.packages("dplyr"); require("dplyr")} # used for species list cleaning
if (!require("tidyr")) {install.packages("tidyr"); require("tidyr")} # used for species list cleaning

```

# Species List Assembly and Cleaning
All non-GBIF species lists were assembled via Excel - see the SpeciesMetaList on Zenodo for dates of database/list accession and list source
The GBIF species list was obtained via:
## TASK: Insert GBIF citation and accession information

Used the GBIF Simple readout for pulling out species information

```{r listreading, echo = FALSE}
# Load GBIF data from the data download
simple <- read.table("~/Research/GBIFNovSimple.csv", sep = '\t', fill = TRUE, header = TRUE)
# head(simple) # use to check import

# select only the species information, and only extract the unique GBIF species entries - the GBIF file is so large, duplicates must be removed as fast as possible to minimize processing time
GBIFspecies <- unique(simple[, 10])

# save unique GBIF results to a new .csv
GBIFResults <- as.data.frame(GBIFspecies)
write.csv(GBIFspecies, '~/Research/GBIFSpecies.csv')

# load non-GBIF data
source <- read.csv('~/Desktop/SpeciesListMetatest.csv', header = TRUE)
# head(source) # use to check import

# pull out unique values and save to a new .csv
sourcetaxa <- unique(source[, 1])
write.csv(sourcetaxa, '~/Research/NonGBIFTaxa.csv')
```

## TASK: Keep an eye out for if the source_binomial name is necessary in the end or not
```{r list_combine, echo = FALSE}
# coerce to a dataframe
sourcedspecies <- as.data.frame(sourcetaxa)

# check headers of both files
# head(GBIFResults)
# head(sourcedspecies)

# set column names
colnames(GBIFResults) <- c('Species')
colnames(sourcedspecies) <- c('Species')

# check headers again
# head(GBIFResults)
# head(sourcedspecies)

# combine columns
MaineSpecList <- rbind(GBIFResults, sourcedspecies)

# Rename header column to fit with Erin's code
#colnames(MaineSpecList) <- 'species_binomial'

# Coerce to dataframe
MaineSpecList <- as.data.frame(MaineSpecList)

# save results
write.csv(MaineSpecList, "C:/Users/bydav/Desktop/RefLib/MaineSpeciesList_Clean.csv")
```

```{r list_cleaning, echo = FALSE}
# load the species list as a vector using scan
encodetest <- scan("C:/Users/bydav/Desktop/MaineSpeciesList_Clean.csv", sep=',', what = "", quiet = TRUE, encoding = "latin1")

# fix capitalization
encodes <- str_to_sentence(encodetest)

# Breaking the vector of names into a dataframe, separating by space so only the first two columns (genus and species) can be joined, while leaving behind any additional information
encodetable <- as.data.frame(encodes) %>% separate(encodes, into = paste("column", 1:23, sep = " "))

# join the species binomial back together
encodetable$source_binomial <- paste0(encodetable$`column 1`, sep=" ", encodetable$`column 2`)

# check for special characters and check the results for any trues
pattern <- "/|:|\\?|<|>|\\|\\\\|\\*"
patternresults <- grepl(pattern, encodetable$source_binomial)

# remove uniques and export to a new file
encodeunique <- unique(encodetable$source_binomial)

cleanlist <- write.csv(encodeunique, "C:/Users/bydav/Desktop/CleanSpecies.csv")
```

By now, we have joined the GBIF and non-GBIF species lists, removed any information except for the species binomial, checked for special characters, standardized capitalization, and removed duplicates. The barebones species list should now be ready for further processing.


# Boundary of Transfer








